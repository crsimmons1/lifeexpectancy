{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNsg2RGsiSAQVrxC/MdmEeB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crsimmons1/lifeexpectancy/blob/master/Classification/Logistic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp62zsb6Vcn4",
        "colab_type": "text"
      },
      "source": [
        "# **Logistic Regression for Classification of Expenditure**\n",
        "## **Introduction**\n",
        "This file uses support vector machines to classify whether the Total Expenditure (general government expenditure on health as a percentage of total government expenditure (%)) was low or high for various countries for the years 2000-2015. The threshold chosen to distinguish low(1)  and high(1) is 5.8%, since it is the median value and keeps the classes balanced.  \n",
        "\n",
        "This data can be found [here](https://www.kaggle.com/kumarajarshi/life-expectancy-who) on Kaggle. Please see this git [repository](https://github.com/crsimmons1/lifeexpectancy) for more information on the data cleaning that was done. \n",
        "\n",
        "The explanatory variables included are:\n",
        "* **LifeExpectancy** in age\n",
        "* **AdultMortality** Adult Mortality Rates of both sexes (probability of dying between 15 and 60 years per 1000 population)\n",
        "* **InfantDeaths** Number of Infant Deaths per 1,000 population\n",
        "* **Alcohol**, recorded per capita (15+) consumption (in litres of pure alcohol)\n",
        "* **HepB** (Hepatitis B) immunization coverage among 1-year-olds (%)\n",
        "* **Measles** - number of reported cases per 1000 population\n",
        "* **BMI** Average Body Mass Index of entire population\n",
        "* **5deaths** Number of under-five deaths per 1000 population\n",
        "* **Polio** (Pol3) immunization coverage among 1-year-olds (%)\n",
        "* **Diphtheria** tetanus toxoid and pertussis (DTP3) immunization coverage among 1-year-olds (%)\n",
        "* **HIV** Deaths per 1,000 live births HIV/AIDS (0-4 years)\n",
        "* **GDP** Gross Domestic Product per capita (in USD)\n",
        "* **Population** of the country\n",
        "* **ThinJuvenile** Prevalence of thinness among children and adolescents for Age 10 to 19 (% )\n",
        "* **ThinChild** Prevalence of thinness among children for Age 5 to 9(%)\n",
        "* **IncomeComp** Human Development Index in terms of income composition of resources (index ranging from 0 to 1)\n",
        "* **Schooling** Number of years of Schooling(years)\n",
        "\n",
        "## **Overview of Analysis and Results**\n",
        "\n",
        "Model 1 was fitted with basic logistic regression. For model 2, all of the variables were scaled. This increased the accuracy 56.4% to 65.7%. Since it is unlikely that all of the features are contributing to the model equally, or at all, the next step is selecting the most important features and dropping the ones that do not contribute. \n",
        "\n",
        "Then, the importance was assessed using recursive feature elimination (RFE) for the next two models. Model 3 removed any features that were below 0.05, which was all three of the immunization variables (Polio, Diphtheria, Measles) and BMI. Model 4 removed the six features that were below 0.1, so Adult Mortality and GDP were also removed. This makes sense considering that GDP and Hepatitis B were both columns with a lot of missing values that were filled in with imputing. Model 4 had the highest accuracy so far, increasing to 65.9%\n",
        "\n",
        "The next step is to tune the parameters to ensure the best possible fit. To avoid overfitting during the process, cross validation is used. The most important parameters are penalty, which helps to avoid having the model overfit, and the strength of that penalty. \n",
        "\n",
        "Model 5 tunes the parameters for penalty and the inverse of the regularization strength using grid search with CV=5. Logistic regression defaults with an l2 penalty, so all available options were considered (l1, none, and elastic net). C is a parameter that indicated the inverse of the regularization strength(larger values specify weaker regularization). A range of this, both above and below 1 will allow us to tune how strong each penalty is. This model improved the accuracy to 66.1%, which is not a great improvement most likely because l2 ended up being the best parameter. C was selected for 0.1, indicating a strong penalty was applied. \n",
        "\n",
        "Model 6 tunes the parameter even further, also using grid search with CV=5. Working with the l2 penalty selected in model 5, several different solvers were put it. A solver is the algorithm used for the optimization problem. The range of possible C values was also increased, with less space between them. A stronger penalty was selected, with C=0.05. The solver selected was newton-cg.  The accuracy decreased slightly to 65.9%. \n",
        "\n",
        "The best model is likely model 6, even with decreased accuracy compared to model 5. It might simply be that model 5 found a local minimum that exists only with cross validation. Model 5 uses a lbfgs solver, which may get stuck at a non-optimal point if the level curves are not smooth. \n",
        "\n",
        "\n",
        "\n",
        "## **Import the Data**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5CoJaYLVZ2Z",
        "colab_type": "code",
        "outputId": "625c5f1f-7d6d-4e72-cdb8-514432c8b53c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# Import Packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Import Unscaled Data\n",
        "data= pd.read_csv(\"cleaned_data.csv\")\n",
        "\n",
        "# Split in X and y \n",
        "y = pd.DataFrame(data.TExp)\n",
        "X = data.drop(columns=['TExpenditure', 'Expenditure','TExp', 'Year', 'Status'])\n",
        "\n",
        "#Train-test split \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=33)\n",
        "\n",
        "data.head(5)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Status</th>\n",
              "      <th>Year</th>\n",
              "      <th>LifeExpectancy</th>\n",
              "      <th>AdultMortality</th>\n",
              "      <th>InfantDeaths</th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Expenditure</th>\n",
              "      <th>HepB</th>\n",
              "      <th>Measles</th>\n",
              "      <th>BMI</th>\n",
              "      <th>5deaths</th>\n",
              "      <th>Polio</th>\n",
              "      <th>TExpenditure</th>\n",
              "      <th>Diphtheria</th>\n",
              "      <th>HIV</th>\n",
              "      <th>GDP</th>\n",
              "      <th>Population</th>\n",
              "      <th>ThinJuvenile</th>\n",
              "      <th>ThinChild</th>\n",
              "      <th>IncomeComp</th>\n",
              "      <th>Schooling</th>\n",
              "      <th>TExp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>263.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>71.279624</td>\n",
              "      <td>65.0</td>\n",
              "      <td>1154.0</td>\n",
              "      <td>19.1</td>\n",
              "      <td>83.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.16</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>584.259210</td>\n",
              "      <td>33736494.0</td>\n",
              "      <td>17.2</td>\n",
              "      <td>17.3</td>\n",
              "      <td>0.479</td>\n",
              "      <td>10.1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>59.9</td>\n",
              "      <td>271.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>73.523582</td>\n",
              "      <td>62.0</td>\n",
              "      <td>492.0</td>\n",
              "      <td>18.6</td>\n",
              "      <td>86.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>8.18</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>612.696514</td>\n",
              "      <td>327582.0</td>\n",
              "      <td>17.5</td>\n",
              "      <td>17.5</td>\n",
              "      <td>0.476</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>59.9</td>\n",
              "      <td>268.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>73.219243</td>\n",
              "      <td>64.0</td>\n",
              "      <td>430.0</td>\n",
              "      <td>18.1</td>\n",
              "      <td>89.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>8.13</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>631.744976</td>\n",
              "      <td>31731688.0</td>\n",
              "      <td>17.7</td>\n",
              "      <td>17.7</td>\n",
              "      <td>0.470</td>\n",
              "      <td>9.9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>59.5</td>\n",
              "      <td>272.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>78.184215</td>\n",
              "      <td>67.0</td>\n",
              "      <td>2787.0</td>\n",
              "      <td>17.6</td>\n",
              "      <td>93.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>8.52</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>669.959000</td>\n",
              "      <td>3696958.0</td>\n",
              "      <td>17.9</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.463</td>\n",
              "      <td>9.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>59.2</td>\n",
              "      <td>275.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>7.097109</td>\n",
              "      <td>68.0</td>\n",
              "      <td>3013.0</td>\n",
              "      <td>17.2</td>\n",
              "      <td>97.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>7.87</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>63.537231</td>\n",
              "      <td>2978599.0</td>\n",
              "      <td>18.2</td>\n",
              "      <td>18.2</td>\n",
              "      <td>0.454</td>\n",
              "      <td>9.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Status    Year  LifeExpectancy  ...  IncomeComp  Schooling  TExp\n",
              "0       0  2015.0            65.0  ...       0.479       10.1     1\n",
              "1       0  2014.0            59.9  ...       0.476       10.0     1\n",
              "2       0  2013.0            59.9  ...       0.470        9.9     1\n",
              "3       0  2012.0            59.5  ...       0.463        9.8     1\n",
              "4       0  2011.0            59.2  ...       0.454        9.5     1\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYFLJ1nsWHit",
        "colab_type": "text"
      },
      "source": [
        "## **Initial Fitting**\n",
        "### Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WohCdqnAYUFc",
        "colab_type": "code",
        "outputId": "9fc19e5e-4d8c-4bd6-a0cd-ebc0a0f74294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUOSjjUdYULU",
        "colab_type": "code",
        "outputId": "e5adc566-a125-4404-a216-349e9546bd72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "y_pred = logreg.predict(X_test)\n",
        "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of logistic regression classifier on test set: 0.56\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.53      0.56       269\n",
            "           1       0.53      0.61      0.57       238\n",
            "\n",
            "    accuracy                           0.56       507\n",
            "   macro avg       0.57      0.57      0.56       507\n",
            "weighted avg       0.57      0.56      0.56       507\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDy0Dx1qvPgr",
        "colab_type": "code",
        "outputId": "1cbe1bf3-3e73-4cde-d887-a23485ec32e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Function to evaluate model \n",
        "RESULTS = {}\n",
        "def evaluate_model(y_test, y_train, y_pred_test, y_pred_train):\n",
        "    return { # First test, then training \n",
        "        # Accuracy\n",
        "        \"Accuracy_test\" : metrics.accuracy_score(y_test, y_pred_test),\n",
        "        \"Accuracy_train\" : metrics.accuracy_score(y_train, y_pred_train),\n",
        "        # AUC\n",
        "        \"AUC_test\" : (metrics.roc_auc_score(y_test, y_pred_test)),\n",
        "        \"AUC_train\" : (metrics.roc_auc_score(y_train, y_pred_train)),\n",
        "        # Average Precision Score\n",
        "        \"AvgPrecision_test\": metrics.average_precision_score(y_test, y_pred_test),\n",
        "        \"AvgPrecision_train\": metrics.average_precision_score(y_train, y_pred_train),\n",
        "        # F1 Score, also known as balanced F-score or F-measure\n",
        "        \"F1_test\": metrics.f1_score(y_test, y_pred_test),\n",
        "        \"F1_train\": metrics.f1_score(y_train, y_pred_train)}\n",
        "\n",
        "# calculate metrics for the training and test predictions\n",
        "y_pred_train = logreg.predict(X_train)\n",
        "y_pred_test = logreg.predict(X_test)\n",
        "RESULTS[\"Initial\"] = evaluate_model(y_test, y_train, y_pred_test,y_pred_train)\n",
        "\n",
        "# Output the metrics\n",
        "pd.DataFrame(RESULTS)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Initial</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AUC_test</th>\n",
              "      <td>0.566462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AUC_train</th>\n",
              "      <td>0.572876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Accuracy_test</th>\n",
              "      <td>0.564103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Accuracy_train</th>\n",
              "      <td>0.571852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AvgPrecision_test</th>\n",
              "      <td>0.506903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AvgPrecision_train</th>\n",
              "      <td>0.534437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1_test</th>\n",
              "      <td>0.565815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1_train</th>\n",
              "      <td>0.599538</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Initial\n",
              "AUC_test            0.566462\n",
              "AUC_train           0.572876\n",
              "Accuracy_test       0.564103\n",
              "Accuracy_train      0.571852\n",
              "AvgPrecision_test   0.506903\n",
              "AvgPrecision_train  0.534437\n",
              "F1_test             0.565815\n",
              "F1_train            0.599538"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlYTVVL6ZEFa",
        "colab_type": "code",
        "outputId": "5c093426-8321-4b6b-a7e8-19ea0560a477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
        "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic - Initial Logistic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('Log_ROC')\n",
        "plt.show()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeLT509-K2mo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "9bb41ad6-fb9e-4588-d89a-292125dc05d6"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "plot_confusion_matrix(logreg, X_test, y_test, values_format='d', cmap='Reds')\n",
        "plt.title(\"Confusion Matrix - Initial Logistic Regression\")\n",
        "plt.show()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2Z8HyC63bzf",
        "colab_type": "text"
      },
      "source": [
        "## **Feature Selection and Scaling**\n",
        "### Model 2 - Scaled "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQvdeXoB3eBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from matplotlib import pyplot\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Create a scaler object\n",
        "sc = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the training data and transform\n",
        "X_train = pd.DataFrame(sc.fit_transform(X_train), columns=X_train.columns)\n",
        "\n",
        "# Apply the scaler to the test data\n",
        "X_test = pd.DataFrame(sc.transform(X_test), columns=X_train.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxjomVtXRepK",
        "colab_type": "code",
        "outputId": "9302a926-8e31-45f9-d30b-d469cd1f5fac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "X_train.head(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LifeExpectancy</th>\n",
              "      <th>AdultMortality</th>\n",
              "      <th>InfantDeaths</th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>HepB</th>\n",
              "      <th>Measles</th>\n",
              "      <th>BMI</th>\n",
              "      <th>5deaths</th>\n",
              "      <th>Polio</th>\n",
              "      <th>Diphtheria</th>\n",
              "      <th>HIV</th>\n",
              "      <th>GDP</th>\n",
              "      <th>Population</th>\n",
              "      <th>ThinJuvenile</th>\n",
              "      <th>ThinChild</th>\n",
              "      <th>IncomeComp</th>\n",
              "      <th>Schooling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.612831</td>\n",
              "      <td>-0.199625</td>\n",
              "      <td>-0.182163</td>\n",
              "      <td>-0.170073</td>\n",
              "      <td>0.499629</td>\n",
              "      <td>-0.201610</td>\n",
              "      <td>-1.703877</td>\n",
              "      <td>-0.196119</td>\n",
              "      <td>0.350160</td>\n",
              "      <td>0.479066</td>\n",
              "      <td>-0.315715</td>\n",
              "      <td>-0.205350</td>\n",
              "      <td>0.029570</td>\n",
              "      <td>-0.787360</td>\n",
              "      <td>-0.800328</td>\n",
              "      <td>0.341004</td>\n",
              "      <td>0.317519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.097265</td>\n",
              "      <td>-0.593504</td>\n",
              "      <td>-0.239988</td>\n",
              "      <td>1.929811</td>\n",
              "      <td>0.737977</td>\n",
              "      <td>-0.201151</td>\n",
              "      <td>0.988580</td>\n",
              "      <td>-0.244786</td>\n",
              "      <td>0.612198</td>\n",
              "      <td>0.651407</td>\n",
              "      <td>-0.315715</td>\n",
              "      <td>1.102629</td>\n",
              "      <td>-0.201657</td>\n",
              "      <td>-0.919042</td>\n",
              "      <td>-0.951772</td>\n",
              "      <td>0.869828</td>\n",
              "      <td>1.222636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.669395</td>\n",
              "      <td>-1.003460</td>\n",
              "      <td>-0.198685</td>\n",
              "      <td>-0.363022</td>\n",
              "      <td>-0.394424</td>\n",
              "      <td>-0.201610</td>\n",
              "      <td>-1.850922</td>\n",
              "      <td>-0.196119</td>\n",
              "      <td>-0.435953</td>\n",
              "      <td>-0.641151</td>\n",
              "      <td>0.647695</td>\n",
              "      <td>-0.479393</td>\n",
              "      <td>-0.199717</td>\n",
              "      <td>0.946452</td>\n",
              "      <td>0.887188</td>\n",
              "      <td>-3.033855</td>\n",
              "      <td>-1.274238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.173030</td>\n",
              "      <td>-0.062973</td>\n",
              "      <td>-0.182163</td>\n",
              "      <td>-1.002009</td>\n",
              "      <td>-1.089356</td>\n",
              "      <td>-0.020234</td>\n",
              "      <td>0.253352</td>\n",
              "      <td>-0.196119</td>\n",
              "      <td>-0.173915</td>\n",
              "      <td>-0.253384</td>\n",
              "      <td>-0.315715</td>\n",
              "      <td>-0.446578</td>\n",
              "      <td>-0.200608</td>\n",
              "      <td>-0.414262</td>\n",
              "      <td>-0.410901</td>\n",
              "      <td>0.134282</td>\n",
              "      <td>-0.400332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.075735</td>\n",
              "      <td>-0.625658</td>\n",
              "      <td>-0.223467</td>\n",
              "      <td>1.330918</td>\n",
              "      <td>0.181832</td>\n",
              "      <td>-0.201610</td>\n",
              "      <td>0.993650</td>\n",
              "      <td>-0.232619</td>\n",
              "      <td>0.524852</td>\n",
              "      <td>0.565236</td>\n",
              "      <td>-0.315715</td>\n",
              "      <td>0.586462</td>\n",
              "      <td>-0.194257</td>\n",
              "      <td>-0.940989</td>\n",
              "      <td>-0.951772</td>\n",
              "      <td>0.932326</td>\n",
              "      <td>1.129003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   LifeExpectancy  AdultMortality  ...  IncomeComp  Schooling\n",
              "0        0.612831       -0.199625  ...    0.341004   0.317519\n",
              "1        1.097265       -0.593504  ...    0.869828   1.222636\n",
              "2       -1.669395       -1.003460  ...   -3.033855  -1.274238\n",
              "3       -0.173030       -0.062973  ...    0.134282  -0.400332\n",
              "4        1.075735       -0.625658  ...    0.932326   1.129003\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98YfXY6_9NTe",
        "colab_type": "code",
        "outputId": "3fbf960c-a4d0-4ed9-e621-62b425a01687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "logreg2 = LogisticRegression()\n",
        "logreg2.fit(X_train, y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLNW0EGs9l2J",
        "colab_type": "code",
        "outputId": "c575a417-83ba-4c50-a5b6-804f75fd89a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "model = LogisticRegression(solver='lbfgs')\n",
        "rfe = RFE(model, 3)\n",
        "fit = rfe.fit(X_train, y_train)\n",
        "print(\"Num Features: %d\" % fit.n_features_)\n",
        "print(\"Selected Features: %s\" % fit.support_)\n",
        "print(\"Feature Ranking: %s\" % fit.ranking_)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Num Features: 3\n",
            "Selected Features: [False False  True  True False False False  True False False False False\n",
            " False False False False False]\n",
            "Feature Ranking: [ 4 11  1  1  9 15 12  1 13 14  3 10  8  7  2  5  6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMbVKphT6mR8",
        "colab_type": "code",
        "outputId": "a19bb696-da1b-4183-e0af-9002039dd3e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "# get importance\n",
        "importance = logreg2.coef_[0]\n",
        "# summarize feature importance\n",
        "for i,v in enumerate(importance):\n",
        "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
        "# plot feature importance\n",
        "pyplot.bar([x for x in range(len(importance))], importance)\n",
        "pyplot.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature: 0, Score: 0.27036\n",
            "Feature: 1, Score: -0.07245\n",
            "Feature: 2, Score: -1.21057\n",
            "Feature: 3, Score: 0.59312\n",
            "Feature: 4, Score: 0.13213\n",
            "Feature: 5, Score: -0.03831\n",
            "Feature: 6, Score: 0.04599\n",
            "Feature: 7, Score: 0.76840\n",
            "Feature: 8, Score: -0.04595\n",
            "Feature: 9, Score: 0.04483\n",
            "Feature: 10, Score: 0.35054\n",
            "Feature: 11, Score: -0.07310\n",
            "Feature: 12, Score: -0.17266\n",
            "Feature: 13, Score: 0.16472\n",
            "Feature: 14, Score: -0.49608\n",
            "Feature: 15, Score: -0.34947\n",
            "Feature: 16, Score: 0.18713\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzlAcgK9TDfM",
        "colab_type": "code",
        "outputId": "09e96a7e-e8ba-4408-cdf1-7f73ceb82d39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "# calculate metrics for the training and test predictions\n",
        "y_pred_train = logreg2.predict(X_train)\n",
        "y_pred_test = logreg2.predict(X_test)\n",
        "RESULTS[\"Scaled\"] = evaluate_model(y_test, y_train, y_pred_test,y_pred_train)\n",
        "\n",
        "# output the predictions\n",
        "pd.DataFrame(RESULTS)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Initial</th>\n",
              "      <th>Scaled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy_test</th>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.656805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Accuracy_train</th>\n",
              "      <td>0.571852</td>\n",
              "      <td>0.693827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AUC_test</th>\n",
              "      <td>0.566462</td>\n",
              "      <td>0.655759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AUC_train</th>\n",
              "      <td>0.572876</td>\n",
              "      <td>0.693733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AvgPrecision_test</th>\n",
              "      <td>0.506903</td>\n",
              "      <td>0.574107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AvgPrecision_train</th>\n",
              "      <td>0.534437</td>\n",
              "      <td>0.628956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1_test</th>\n",
              "      <td>0.565815</td>\n",
              "      <td>0.635983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1_train</th>\n",
              "      <td>0.599538</td>\n",
              "      <td>0.688755</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Initial    Scaled\n",
              "Accuracy_test       0.564103  0.656805\n",
              "Accuracy_train      0.571852  0.693827\n",
              "AUC_test            0.566462  0.655759\n",
              "AUC_train           0.572876  0.693733\n",
              "AvgPrecision_test   0.506903  0.574107\n",
              "AvgPrecision_train  0.534437  0.628956\n",
              "F1_test             0.565815  0.635983\n",
              "F1_train            0.599538  0.688755"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8tI46xRxrAD",
        "colab_type": "text"
      },
      "source": [
        "### Model 3 - remove 4 features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeI4pS3bTWdM",
        "colab_type": "code",
        "outputId": "deffc9aa-6aae-4ce6-a85a-7de87323fde6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Now remove features 5,6,8 and 9 \n",
        "X_train.columns\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['LifeExpectancy', 'AdultMortality', 'InfantDeaths', 'Alcohol', 'HepB',\n",
              "       'Measles', 'BMI', '5deaths', 'Polio', 'Diphtheria', 'HIV', 'GDP',\n",
              "       'Population', 'ThinJuvenile', 'ThinChild', 'IncomeComp', 'Schooling'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbguKj5zU5yz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.drop(columns=['Measles', 'BMI','Polio', 'Diphtheria'])\n",
        "X_test = X_test.drop(columns=['Measles', 'BMI','Polio', 'Diphtheria'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoW-hQnrVNPo",
        "colab_type": "code",
        "outputId": "78e80fed-b5d6-4ee7-93a5-63974aea0fbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "# Fit new model \n",
        "logreg3 = LogisticRegression()\n",
        "logreg3.fit(X_train, y_train)\n",
        "\n",
        "#Make predictions \n",
        "y_pred_train = logreg3.predict(X_train)\n",
        "y_pred_test = logreg3.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "RESULTS[\"Scaled_drop4\"] = evaluate_model(y_test, y_train, y_pred_test,y_pred_train)\n",
        "pd.DataFrame(RESULTS)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Initial</th>\n",
              "      <th>Scaled</th>\n",
              "      <th>Scaled_drop4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy_test</th>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.656805</td>\n",
              "      <td>0.654832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Accuracy_train</th>\n",
              "      <td>0.571852</td>\n",
              "      <td>0.693827</td>\n",
              "      <td>0.696296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AUC_test</th>\n",
              "      <td>0.566462</td>\n",
              "      <td>0.655759</td>\n",
              "      <td>0.654384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AUC_train</th>\n",
              "      <td>0.572876</td>\n",
              "      <td>0.693733</td>\n",
              "      <td>0.696196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AvgPrecision_test</th>\n",
              "      <td>0.506903</td>\n",
              "      <td>0.574107</td>\n",
              "      <td>0.572403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AvgPrecision_train</th>\n",
              "      <td>0.534437</td>\n",
              "      <td>0.628956</td>\n",
              "      <td>0.631219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1_test</th>\n",
              "      <td>0.565815</td>\n",
              "      <td>0.635983</td>\n",
              "      <td>0.637681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1_train</th>\n",
              "      <td>0.599538</td>\n",
              "      <td>0.688755</td>\n",
              "      <td>0.691110</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Initial    Scaled  Scaled_drop4\n",
              "Accuracy_test       0.564103  0.656805      0.654832\n",
              "Accuracy_train      0.571852  0.693827      0.696296\n",
              "AUC_test            0.566462  0.655759      0.654384\n",
              "AUC_train           0.572876  0.693733      0.696196\n",
              "AvgPrecision_test   0.506903  0.574107      0.572403\n",
              "AvgPrecision_train  0.534437  0.628956      0.631219\n",
              "F1_test             0.565815  0.635983      0.637681\n",
              "F1_train            0.599538  0.688755      0.691110"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITxbamOFxxcw",
        "colab_type": "text"
      },
      "source": [
        "### Model 4 - remove 6 total features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtYEsWmoVNXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now drop feature 1 and 11\n",
        "X_train = X_train.drop(columns=['AdultMortality', 'GDP'])\n",
        "X_test = X_test.drop(columns=['AdultMortality', 'GDP'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sALR8vHoX49q",
        "colab_type": "code",
        "outputId": "55ab6a6c-e466-4332-b7ea-d52dfc88dba0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "# Fit new model \n",
        "logreg3.fit(X_train, y_train)\n",
        "\n",
        "#Make predictions \n",
        "y_pred_train = logreg3.predict(X_train)\n",
        "y_pred_test = logreg3.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "RESULTS[\"Scaled_drop6\"] = evaluate_model(y_test, y_train, y_pred_test,y_pred_train)\n",
        "pd.DataFrame(RESULTS)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Initial</th>\n",
              "      <th>Scaled</th>\n",
              "      <th>Scaled_drop4</th>\n",
              "      <th>Scaled_drop6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy_test</th>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.656805</td>\n",
              "      <td>0.654832</td>\n",
              "      <td>0.658777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Accuracy_train</th>\n",
              "      <td>0.571852</td>\n",
              "      <td>0.693827</td>\n",
              "      <td>0.696296</td>\n",
              "      <td>0.700247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AUC_test</th>\n",
              "      <td>0.566462</td>\n",
              "      <td>0.655759</td>\n",
              "      <td>0.654384</td>\n",
              "      <td>0.657618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AUC_train</th>\n",
              "      <td>0.572876</td>\n",
              "      <td>0.693733</td>\n",
              "      <td>0.696196</td>\n",
              "      <td>0.700082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AvgPrecision_test</th>\n",
              "      <td>0.506903</td>\n",
              "      <td>0.574107</td>\n",
              "      <td>0.572403</td>\n",
              "      <td>0.575799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AvgPrecision_train</th>\n",
              "      <td>0.534437</td>\n",
              "      <td>0.628956</td>\n",
              "      <td>0.631219</td>\n",
              "      <td>0.635175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1_test</th>\n",
              "      <td>0.565815</td>\n",
              "      <td>0.635983</td>\n",
              "      <td>0.637681</td>\n",
              "      <td>0.637317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1_train</th>\n",
              "      <td>0.599538</td>\n",
              "      <td>0.688755</td>\n",
              "      <td>0.691110</td>\n",
              "      <td>0.693589</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Initial    Scaled  Scaled_drop4  Scaled_drop6\n",
              "Accuracy_test       0.564103  0.656805      0.654832      0.658777\n",
              "Accuracy_train      0.571852  0.693827      0.696296      0.700247\n",
              "AUC_test            0.566462  0.655759      0.654384      0.657618\n",
              "AUC_train           0.572876  0.693733      0.696196      0.700082\n",
              "AvgPrecision_test   0.506903  0.574107      0.572403      0.575799\n",
              "AvgPrecision_train  0.534437  0.628956      0.631219      0.635175\n",
              "F1_test             0.565815  0.635983      0.637681      0.637317\n",
              "F1_train            0.599538  0.688755      0.691110      0.693589"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RUEQW_RWJ9Z",
        "colab_type": "text"
      },
      "source": [
        "## **Parameter Tuning with Grid Search**\n",
        "### Model 5 - Penalty and Inverse of Regularization Strength\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pwa18bFcLVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV \n",
        "\n",
        "# Set paramters to be tuned\n",
        "param_grid = { \n",
        "    'penalty': ['l1','elasticnet','l2', 'none'], \n",
        "    'C': [0.01,0.1,0.5,1,2,5,10]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI-0cWlJr2yE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid = GridSearchCV(estimator = logreg, param_grid=param_grid, \n",
        "                          cv = 5, verbose = 51, n_jobs=-1)\n",
        "\n",
        "logreg = LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kLcXSufr8t5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "099377b8-229c-4504-8b0d-0699d23e0230"
      },
      "source": [
        "import time \n",
        "\n",
        "t_start = time.time()\n",
        "grid.fit(X_train, y_train)\n",
        "t_end = time.time()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0139s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0233s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1128s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1777s.) Setting batch_size=16.\n",
            "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done 108 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done 111 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=-1)]: Done 115 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=-1)]: Done 117 tasks      | elapsed:    1.2s\n",
            "[Parallel(n_jobs=-1)]: Done 118 tasks      | elapsed:    1.2s\n",
            "[Parallel(n_jobs=-1)]: Done 119 tasks      | elapsed:    1.2s\n",
            "[Parallel(n_jobs=-1)]: Done 135 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:    1.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:    1.3s finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT55T-qisCUM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "cb495681-d252-4b31-feff-3c32e58fdf5e"
      },
      "source": [
        "best = grid.best_estimator_\n",
        "best"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfYXB__5u4oJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "fbb587f0-9522-49b5-a585-227a547dc7bf"
      },
      "source": [
        "# Fit new model \n",
        "best.fit(X_train, y_train)\n",
        "\n",
        "#Make predictions \n",
        "y_pred_train = best.predict(X_train)\n",
        "y_pred_test = best.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "RESULTS[\"Scaled_tuned\"] = evaluate_model(y_test, y_train, y_pred_test,y_pred_train)\n",
        "pd.DataFrame(RESULTS)\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Initial</th>\n",
              "      <th>Scaled</th>\n",
              "      <th>Scaled_drop4</th>\n",
              "      <th>Scaled_drop6</th>\n",
              "      <th>Scaled_tuned</th>\n",
              "      <th>Scaled_tuned2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy_test</th>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.656805</td>\n",
              "      <td>0.654832</td>\n",
              "      <td>0.658777</td>\n",
              "      <td>0.660750</td>\n",
              "      <td>0.658777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Accuracy_train</th>\n",
              "      <td>0.571852</td>\n",
              "      <td>0.693827</td>\n",
              "      <td>0.696296</td>\n",
              "      <td>0.700247</td>\n",
              "      <td>0.702716</td>\n",
              "      <td>0.701235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AUC_test</th>\n",
              "      <td>0.566462</td>\n",
              "      <td>0.655759</td>\n",
              "      <td>0.654384</td>\n",
              "      <td>0.657618</td>\n",
              "      <td>0.659234</td>\n",
              "      <td>0.657376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AUC_train</th>\n",
              "      <td>0.572876</td>\n",
              "      <td>0.693733</td>\n",
              "      <td>0.696196</td>\n",
              "      <td>0.700082</td>\n",
              "      <td>0.702584</td>\n",
              "      <td>0.701122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AvgPrecision_test</th>\n",
              "      <td>0.506903</td>\n",
              "      <td>0.574107</td>\n",
              "      <td>0.572403</td>\n",
              "      <td>0.575799</td>\n",
              "      <td>0.577541</td>\n",
              "      <td>0.575828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AvgPrecision_train</th>\n",
              "      <td>0.534437</td>\n",
              "      <td>0.628956</td>\n",
              "      <td>0.631219</td>\n",
              "      <td>0.635175</td>\n",
              "      <td>0.637262</td>\n",
              "      <td>0.635790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1_test</th>\n",
              "      <td>0.565815</td>\n",
              "      <td>0.635983</td>\n",
              "      <td>0.637681</td>\n",
              "      <td>0.637317</td>\n",
              "      <td>0.637131</td>\n",
              "      <td>0.635789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1_train</th>\n",
              "      <td>0.599538</td>\n",
              "      <td>0.688755</td>\n",
              "      <td>0.691110</td>\n",
              "      <td>0.693589</td>\n",
              "      <td>0.696878</td>\n",
              "      <td>0.695827</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Initial    Scaled  ...  Scaled_tuned  Scaled_tuned2\n",
              "Accuracy_test       0.564103  0.656805  ...      0.660750       0.658777\n",
              "Accuracy_train      0.571852  0.693827  ...      0.702716       0.701235\n",
              "AUC_test            0.566462  0.655759  ...      0.659234       0.657376\n",
              "AUC_train           0.572876  0.693733  ...      0.702584       0.701122\n",
              "AvgPrecision_test   0.506903  0.574107  ...      0.577541       0.575828\n",
              "AvgPrecision_train  0.534437  0.628956  ...      0.637262       0.635790\n",
              "F1_test             0.565815  0.635983  ...      0.637131       0.635789\n",
              "F1_train            0.599538  0.688755  ...      0.696878       0.695827\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8qAep5117e1",
        "colab_type": "text"
      },
      "source": [
        "### Model 6 - Tune Inverse of Regularization Strength and Solver for l2 Penalty"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNTVfENH1_x8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV \n",
        "\n",
        "# Set paramters to be tuned\n",
        "param_grid2 = { \n",
        "    'C': [0.01,0.05,0.1,0.25,0.5,1],\n",
        "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XyKBfsf29vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid2 = GridSearchCV(estimator = logreg, param_grid=param_grid2, \n",
        "                          cv = 5, verbose = 51, n_jobs=-1)\n",
        "\n",
        "logreg = LogisticRegression(penalty='l2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRzF0YRy3BP2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "outputId": "53db0590-7ba0-495f-a438-2a6f6b2d4888"
      },
      "source": [
        "import time \n",
        "\n",
        "t_start = time.time()\n",
        "grid2.fit(X_train, y_train)\n",
        "t_end = time.time()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.2s\n",
            "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.2s\n",
            "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1736s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0596s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1468s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.8s\n",
            "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    2.1s\n",
            "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    2.2s\n",
            "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:    2.6s\n",
            "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:    2.9s\n",
            "[Parallel(n_jobs=-1)]: Done 106 tasks      | elapsed:    3.0s\n",
            "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed:    3.4s\n",
            "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    3.5s\n",
            "[Parallel(n_jobs=-1)]: Done 131 tasks      | elapsed:    3.5s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    3.5s\n",
            "[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed:    3.6s\n",
            "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:    3.6s\n",
            "[Parallel(n_jobs=-1)]: Done 142 tasks      | elapsed:    3.6s\n",
            "[Parallel(n_jobs=-1)]: Done 143 tasks      | elapsed:    3.6s\n",
            "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:    3.7s\n",
            "[Parallel(n_jobs=-1)]: Done 145 tasks      | elapsed:    3.7s\n",
            "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    3.7s\n",
            "[Parallel(n_jobs=-1)]: Done 147 tasks      | elapsed:    3.8s\n",
            "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:    3.9s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:    3.9s finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a46p3U53Ln4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4fdac92c-74c2-4950-91cb-719b8202c811"
      },
      "source": [
        "best2 = grid2.best_estimator_\n",
        "best2"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.05, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFDPjS1f3Tbp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "83ed0c65-df55-4213-fed3-fc764ecf4f86"
      },
      "source": [
        "# Fit new model \n",
        "best2.fit(X_train, y_train)\n",
        "\n",
        "#Make predictions \n",
        "y_pred_train = best2.predict(X_train)\n",
        "y_pred_test = best2.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "RESULTS[\"Scaled_tuned2\"] = evaluate_model(y_test, y_train, y_pred_test,y_pred_train)\n",
        "pd.DataFrame(RESULTS)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Initial</th>\n",
              "      <th>Scaled</th>\n",
              "      <th>Scaled_drop4</th>\n",
              "      <th>Scaled_drop6</th>\n",
              "      <th>Scaled_tuned</th>\n",
              "      <th>Scaled_tuned2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy_test</th>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.656805</td>\n",
              "      <td>0.654832</td>\n",
              "      <td>0.658777</td>\n",
              "      <td>0.660750</td>\n",
              "      <td>0.658777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Accuracy_train</th>\n",
              "      <td>0.571852</td>\n",
              "      <td>0.693827</td>\n",
              "      <td>0.696296</td>\n",
              "      <td>0.700247</td>\n",
              "      <td>0.702716</td>\n",
              "      <td>0.701235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AUC_test</th>\n",
              "      <td>0.566462</td>\n",
              "      <td>0.655759</td>\n",
              "      <td>0.654384</td>\n",
              "      <td>0.657618</td>\n",
              "      <td>0.659234</td>\n",
              "      <td>0.657376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AUC_train</th>\n",
              "      <td>0.572876</td>\n",
              "      <td>0.693733</td>\n",
              "      <td>0.696196</td>\n",
              "      <td>0.700082</td>\n",
              "      <td>0.702584</td>\n",
              "      <td>0.701122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AvgPrecision_test</th>\n",
              "      <td>0.506903</td>\n",
              "      <td>0.574107</td>\n",
              "      <td>0.572403</td>\n",
              "      <td>0.575799</td>\n",
              "      <td>0.577541</td>\n",
              "      <td>0.575828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AvgPrecision_train</th>\n",
              "      <td>0.534437</td>\n",
              "      <td>0.628956</td>\n",
              "      <td>0.631219</td>\n",
              "      <td>0.635175</td>\n",
              "      <td>0.637262</td>\n",
              "      <td>0.635790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1_test</th>\n",
              "      <td>0.565815</td>\n",
              "      <td>0.635983</td>\n",
              "      <td>0.637681</td>\n",
              "      <td>0.637317</td>\n",
              "      <td>0.637131</td>\n",
              "      <td>0.635789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1_train</th>\n",
              "      <td>0.599538</td>\n",
              "      <td>0.688755</td>\n",
              "      <td>0.691110</td>\n",
              "      <td>0.693589</td>\n",
              "      <td>0.696878</td>\n",
              "      <td>0.695827</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Initial    Scaled  ...  Scaled_tuned  Scaled_tuned2\n",
              "Accuracy_test       0.564103  0.656805  ...      0.660750       0.658777\n",
              "Accuracy_train      0.571852  0.693827  ...      0.702716       0.701235\n",
              "AUC_test            0.566462  0.655759  ...      0.659234       0.657376\n",
              "AUC_train           0.572876  0.693733  ...      0.702584       0.701122\n",
              "AvgPrecision_test   0.506903  0.574107  ...      0.577541       0.575828\n",
              "AvgPrecision_train  0.534437  0.628956  ...      0.637262       0.635790\n",
              "F1_test             0.565815  0.635983  ...      0.637131       0.635789\n",
              "F1_train            0.599538  0.688755  ...      0.696878       0.695827\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dydzK3bHAQcV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "56cfc1b9-e842-46fa-c5fe-97fcf03ac08d"
      },
      "source": [
        "# plot curve\n",
        "logit_roc_auc = roc_auc_score(y_test, best2.predict(X_test))\n",
        "fpr, tpr, thresholds = roc_curve(y_test, best2.predict_proba(X_test)[:,1])\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic - Best Logistic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('Log_ROC')\n",
        "plt.show()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-36d62cf37b3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogit_roc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Logistic Regression (area = %0.2f)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlogit_roc_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 273\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
            "\u001b[0;31mValueError\u001b[0m: X has 17 features per sample; expecting 11"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSANOGOMIoOk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a3a6dc4a-8d72-470a-9ae9-184c245bf5bb"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "plot_confusion_matrix(best2, X_test, y_test, values_format='d', cmap='Reds')\n",
        "plt.title(\"Confusion Matrix - Best Logistic Regression\")\n",
        "plt.show()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}